{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e329938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Extraction using RANSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51677554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e864e5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images\n",
    "img1_color=cv2.imread('./left.jpg')# Query image\n",
    "img2_color=cv2.imread('./right.jpg')# train image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85336698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to grayscale\n",
    "img1=cv2.cvtColor(img1_color,cv2.COLOR_BGR2GRAY)\n",
    "img2=cv2.cvtColor(img2_color,cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "013621f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SIFT detectoe\n",
    "sift=cv2.SIFT_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2340695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect the keypoints and compute desciptors\n",
    "kp1, des1 =sift.detectAndCompute(img1, None)\n",
    "kp2, des2 =sift.detectAndCompute(img2, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731b4716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLANN parameters and matcher setup\n",
    "FLANN_INDEX_KDTREE=1\n",
    "index_params = dict(algorithm-FLANN_INDEX_KDTREE, trees=5)\n",
    "search_params = dict(checks=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aa056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "flann=cv2.FlannBasedMatcher(index_params, search_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dce9094",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Match Descriptors using KNN\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m matches\u001b[38;5;241m-\u001b[39mflann\u001b[38;5;241m.\u001b[39mknnmatch(des1, des2, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'matches' is not defined"
     ]
    }
   ],
   "source": [
    "# Match Descriptors using KNN\n",
    "matches-flann.knnmatch(des1, des2, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76d4bdee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ratio Test to keep good matches\u001b[39;00m\n\u001b[0;32m      2\u001b[0m good\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m, n \u001b[38;5;129;01min\u001b[39;00m matches:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mdistance\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m0.7\u001b[39m\u001b[38;5;241m*\u001b[39mn\u001b[38;5;241m.\u001b[39mdistance:\n\u001b[0;32m      5\u001b[0m         good,append(m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'matches' is not defined"
     ]
    }
   ],
   "source": [
    "# Ratio Test to keep good matches\n",
    "good=[]\n",
    "for m, n in matches:\n",
    "    if m.distance<0.7*n.distance:\n",
    "        good,append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd0d85b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (1701113486.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    points1=np.zeros((len(good),2)dtype=np.float32)\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "# Extracting locations of good matches\n",
    "points1=np.zeros((len(good),2)dtype=np.float32)\n",
    "points2=np.zeros((len(good),2)dtype=np.float32)\n",
    "\n",
    "for i, match in enumerate(good):\n",
    "    points1[i,:]=kp1[match.queryIdx].pt\n",
    "    points2[i,:]=kp2[match.trainIdx].pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd5c4a85",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'H' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# find the ehomography using RANSAC\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m H,status\u001b[38;5;241m-\u001b[39mcv2\u001b[38;5;241m.\u001b[39mfindHomography(points1,points2,cv2,RANSAC)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'H' is not defined"
     ]
    }
   ],
   "source": [
    "# find the ehomography using RANSAC\n",
    "H,status-cv2.findHomography(points1,points2,cv2,RANSAC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f52faa68",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'height' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#create new image thatputs two images side by side\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m height\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mmax\u001b[39m(img1_color\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],img2_color\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      3\u001b[0m width\u001b[38;5;241m=\u001b[39mimg1_color\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],img2_color\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      4\u001b[0m output\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mzeros((height,width,\u001b[38;5;241m3\u001b[39m),dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'height' is not defined"
     ]
    }
   ],
   "source": [
    "#create new image thatputs two images side by side\n",
    "height-max(img1_color.shape[0],img2_color.shape[0])\n",
    "width=img1_color.shape[1],img2_color.shape[1]\n",
    "output=np.zeros((height,width,3),dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f99614e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (3367180924.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[11], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "#place both images withing this new image\n",
    "output[0:img1_color.shape[0], 0:img1_color.shape[1]] = im\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b32a658",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (248788228.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[12], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    for i, (m,color) in enumerate(zip(good, np.random.randint(0,255,(len(good),3)))\u001b[0m\n\u001b[1;37m                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "# Draw Lines Between the matchinh points\n",
    "for i, (m,color) in enumerate(zip(good, np.random.randint(0,255,(len(good),3)))\n",
    "    if status[i]:\n",
    "        plt1=tuple(map(int,kp1[m.queryIdx].pt))\n",
    "        plt2=tuple(map(int,kp2[m.queryIdx].pt))\n",
    "        pt2=(pt2[0]+img_color.shape[1],pt2[1])\n",
    "                              \n",
    "        cv2.line(output, pt1, pt2, color.tolist(), 2)\n",
    "\n",
    "# convert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8f54bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image stiching\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26d6c2e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "imread() missing required argument 'filename' (pos 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Load the color images\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m img1_left \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread()\n\u001b[0;32m      3\u001b[0m img2_right \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread()\n",
      "\u001b[1;31mTypeError\u001b[0m: imread() missing required argument 'filename' (pos 1)"
     ]
    }
   ],
   "source": [
    "#Load the color images\n",
    "img_left = cv2.imread()\n",
    "img_right = cv2.imread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6573f802",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'cvtcolor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Convert to grayscale\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m img1\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mcvtcolor(img1_color,cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m      3\u001b[0m img2_\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mcvtcolor(img2_color,cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'cvtcolor'"
     ]
    }
   ],
   "source": [
    "# Convert to grayscale\n",
    "img1=cv2.cvtcolor(img1_color,cv2.COLOR_BGR2GRAY)\n",
    "img2_=cv2.cvtcolor(img2_color,cv2.COLOR_BGR2GRAY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7cb9858",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sift' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Detect the keypoints and compute desciptors\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m kp1, des1 \u001b[38;5;241m=\u001b[39msift\u001b[38;5;241m.\u001b[39mdetectAndCompute(img1, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m kp2, des2 \u001b[38;5;241m=\u001b[39msift\u001b[38;5;241m.\u001b[39mdetectAndCompute(img2, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sift' is not defined"
     ]
    }
   ],
   "source": [
    "# Detect the keypoints and compute desciptors\n",
    "kp1, des1 =sift.detectAndCompute(img1, None)\n",
    "kp2, des2 =sift.detectAndCompute(img2, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dac37db9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'BFMAtcher'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# create Brutforce Matcher object\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m bf\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mBFMAtcher(cv2\u001b[38;5;241m.\u001b[39mNORM_L2, crosCheck\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'BFMAtcher'"
     ]
    }
   ],
   "source": [
    "# create Brutforce Matcher object\n",
    "bf=cv2.BFMAtcher(cv2.NORM_L2, crosCheck=False)\n",
    "\n",
    "# perform the matching between SIFT descriptors\n",
    "matches=bf.KNNMatch(des1,des2,k=2)\n",
    "\n",
    "# apply ratio test\n",
    "good[]\n",
    "form,n in matches:\n",
    "    if m.distance<0.75*n.distance:\n",
    "        good.append(m)\n",
    "        \n",
    "# atleast 4 matches tp find homography\n",
    "if len(good)>4:\n",
    "    #prepare source and destination points\n",
    "\n",
    "    src_pts=np.float32([kp1[m.querIdx].pt for m in good]).reshape(-1,1,2)\n",
    "    dst_pts=np.float32([kp2[m.querIdx].pt for m in good]).reshape(-1,1,2)\n",
    "    \n",
    "    # computer Homography\n",
    "    H, status=cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "    \n",
    "    # use homography to wrap image\n",
    "    dst=cv2.warpPerspective(img_right,H, (img_left.shape[1]+img_right.shape[1],\n",
    "                                         img_left.shape[0]))\n",
    "    \n",
    "    #place left image on appropriate position\n",
    "    dst[0:img_left.shape[0],0:img_left.shape[1]]=image_left\n",
    "    \n",
    "    # convert to grayscale to find the mask of stujed images\n",
    "    gray=cv2.cvtcolor(dst,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    _,mask-cv3=2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # find the contours in the mask\n",
    "    coutours,_=cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    #find the largest Countour foe the outline of the stiched image\n",
    "    max_contour = max(contours,key=cv2.contourArea)\n",
    "    \n",
    "    # get the bounding rectangele for target contour\n",
    "    x,yw,h -cv2.boundingRect(max_contour)\n",
    "    \n",
    "    # crop the stiched image using the bounding rectangle\n",
    "    cropped_stiched = dst[y:y+h,x:x+w]\n",
    "    \n",
    "    # save the cropped stiched image\n",
    "    cv2.imwrite('cropped_output.jpg',cropped_stiched)\n",
    "    \n",
    "    # convert images from BGR to RGB for display\n",
    "    img_left_rgb=cv2.cvtcolor(img_left,cv2.COLOR_BGR2RGB)\n",
    "        img_left_rgb=cv2.cvtcolor(img_left,cv2.COLOR_BGR2RGB)\n",
    "        img_right_rgb=cv2.cvtcolor(img_right,cv2.COLOR_BGR2RGB\n",
    "        cropped_stiched_rgb=cv2.cvtcolor(cropped_stiched,cv2.BGR2RGB)\n",
    "                                   \n",
    "    # Display the two orginial images\n",
    "    plt.figure(figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9051927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
